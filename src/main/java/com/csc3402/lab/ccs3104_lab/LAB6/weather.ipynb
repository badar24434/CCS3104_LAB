{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e320ee9",
   "metadata": {},
   "source": [
    "# Weather Data Engineering Pipeline - Google Colab Version\n",
    "# =========================================================\n",
    "Run this notebook in Google Colab for a complete data engineering workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d865e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Setup and Installation\n",
    "print(\"Installing dependencies...\")\n",
    "!pip install -q pyspark requests great-expectations plotly sqlalchemy\n",
    "\n",
    "print(\"Setup complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "886d70b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Import Libraries\n",
    "import requests\n",
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.window import Window\n",
    "import json\n",
    "from datetime import datetime\n",
    "import time\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d682cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Initialize Spark Session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"WeatherPipeline\") \\\n",
    "    .config(\"spark.sql.repl.eagerEval.enabled\", True) \\\n",
    "    .config(\"spark.driver.memory\", \"4g\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")\n",
    "print(f\"Spark version: {spark.version}\")\n",
    "print(\"Spark session initialized!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf2a13a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Configuration\n",
    "# Get your free API key from: https://openweathermap.org/api\n",
    "API_KEY = \"34a91dc9a353902fd151448547fde35c\"  # Replace with your API key\n",
    "\n",
    "CITIES = [\n",
    "    \"London,UK\", \"New York,US\", \"Tokyo,JP\", \"Paris,FR\",\n",
    "    \"Sydney,AU\", \"Mumbai,IN\", \"Singapore,SG\", \"Dubai,AE\",\n",
    "    \"Toronto,CA\", \"Berlin,DE\", \"SÃ£o Paulo,BR\", \"Moscow,RU\"\n",
    "]\n",
    "\n",
    "BASE_URL = \"http://api.openweathermap.org/data/2.5/weather\"\n",
    "\n",
    "print(f\"Pipeline configured for {len(CITIES)} cities\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de4aab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Extract - Fetch Weather Data from API\n",
    "def extract_weather_data(api_key, cities, base_url):\n",
    "    \"\"\"Extract current weather data from OpenWeatherMap API\"\"\"\n",
    "    weather_data = []\n",
    "    failed_cities = []\n",
    "\n",
    "    print(f\"Extracting data for {len(cities)} cities...\")\n",
    "\n",
    "    for city in cities:\n",
    "        try:\n",
    "            params = {\n",
    "                'q': city,\n",
    "                'appid': api_key,\n",
    "                'units': 'metric'\n",
    "            }\n",
    "            response = requests.get(base_url, params=params, timeout=10)\n",
    "            response.raise_for_status()\n",
    "            data = response.json()\n",
    "\n",
    "            # Flatten nested JSON structure\n",
    "            # Ensure numeric fields that might vary between int/float are cast to float for consistent schema inference\n",
    "            flattened = {\n",
    "                'city': data['name'],\n",
    "                'country': data['sys']['country'],\n",
    "                'latitude': float(data['coord']['lat']),\n",
    "                'longitude': float(data['coord']['lon']),\n",
    "                'temperature': float(data['main']['temp']),\n",
    "                'feels_like': float(data['main']['feels_like']),\n",
    "                'temp_min': float(data['main']['temp_min']),\n",
    "                'temp_max': float(data['main']['temp_max']),\n",
    "                'pressure': float(data['main']['pressure']),\n",
    "                'humidity': float(data['main']['humidity']),\n",
    "                'weather_main': data['weather'][0]['main'],\n",
    "                'weather_description': data['weather'][0]['description'],\n",
    "                'wind_speed': float(data['wind']['speed']),\n",
    "                'wind_deg': float(data['wind'].get('deg', 0)),\n",
    "                'clouds': float(data['clouds']['all']),\n",
    "                'visibility': float(data.get('visibility', 10000)),\n",
    "                'rain_1h': float(data.get('rain', {}).get('1h', 0)),\n",
    "                'snow_1h': float(data.get('snow', {}).get('1h', 0)),\n",
    "                'sunrise': float(data['sys']['sunrise']),\n",
    "                'sunset': float(data['sys']['sunset']),\n",
    "                'timezone': float(data['timezone']),\n",
    "                'timestamp': float(data['dt']),\n",
    "                'extraction_time': datetime.now().isoformat()\n",
    "            }\n",
    "            weather_data.append(flattened)\n",
    "            print(f\"âœ“ {city}\")\n",
    "            time.sleep(0.3)  # Rate limiting\n",
    "\n",
    "        except Exception as e:\n",
    "            failed_cities.append(city)\n",
    "            print(f\"âœ— {city}: {str(e)}\")\n",
    "\n",
    "    print(f\"\\nSuccessfully extracted: {len(weather_data)}/{len(cities)} cities\")\n",
    "    if failed_cities:\n",
    "        print(f\"Failed cities: {', '.join(failed_cities)}\")\n",
    "\n",
    "    return weather_data\n",
    "\n",
    "# Execute extraction\n",
    "raw_data = extract_weather_data(API_KEY, CITIES, BASE_URL)\n",
    "\n",
    "# Display sample\n",
    "if raw_data:\n",
    "    print(\"\\nSample raw data:\")\n",
    "    print(json.dumps(raw_data[0], indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b375c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Load Raw Data into Spark DataFrame\n",
    "if not raw_data:\n",
    "    raise ValueError(\"No data extracted! Check your API key and internet connection.\")\n",
    "\n",
    "df_raw = spark.createDataFrame(raw_data)\n",
    "print(f\"Raw DataFrame created with {df_raw.count()} rows and {len(df_raw.columns)} columns\")\n",
    "print(\"\\nSchema:\")\n",
    "df_raw.printSchema()\n",
    "print(\"\\nSample data:\")\n",
    "df_raw.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c7ea0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Transform - Data Processing with PySpark\n",
    "def transform_weather_data(df):\n",
    "    \"\"\"Apply comprehensive transformations to weather data\"\"\"\n",
    "\n",
    "    # Datetime conversions\n",
    "    df_transformed = df \\\n",
    "        .withColumn('date', from_unixtime(col('timestamp')).cast('date')) \\\n",
    "        .withColumn('datetime', from_unixtime(col('timestamp')).cast('timestamp')) \\\n",
    "        .withColumn('hour', hour(from_unixtime(col('timestamp')))) \\\n",
    "        .withColumn('day_of_week', date_format(from_unixtime(col('timestamp')), 'EEEE')) \\\n",
    "        .withColumn('sunrise_time', from_unixtime(col('sunrise')).cast('timestamp')) \\\n",
    "        .withColumn('sunset_time', from_unixtime(col('sunset')).cast('timestamp'))\n",
    "\n",
    "    # Derived metrics\n",
    "    df_transformed = df_transformed \\\n",
    "        .withColumn('temp_range', col('temp_max') - col('temp_min')) \\\n",
    "        .withColumn('is_raining', when(col('rain_1h') > 0, True).otherwise(False)) \\\n",
    "        .withColumn('is_snowing', when(col('snow_1h') > 0, True).otherwise(False)) \\\n",
    "        .withColumn('visibility_km', col('visibility') / 1000)\n",
    "\n",
    "    # Categorizations\n",
    "    df_transformed = df_transformed \\\n",
    "        .withColumn('temp_category',\n",
    "                   when(col('temperature') < 0, 'Freezing')\\\n",
    "                   .when(col('temperature') < 10, 'Cold')\\\n",
    "                   .when(col('temperature') < 20, 'Cool')\\\n",
    "                   .when(col('temperature') < 25, 'Moderate')\\\n",
    "                   .when(col('temperature') < 30, 'Warm')\\\n",
    "                   .otherwise('Hot')) \\\n",
    "        .withColumn('humidity_category',\n",
    "                   when(col('humidity') < 30, 'Low')\\\n",
    "                   .when(col('humidity') < 60, 'Moderate')\\\n",
    "                   .otherwise('High')) \\\n",
    "        .withColumn('wind_category',\n",
    "                   when(col('wind_speed') < 5, 'Calm')\\\n",
    "                   .when(col('wind_speed') < 10, 'Light')\\\n",
    "                   .when(col('wind_speed') < 20, 'Moderate')\\\n",
    "                   .otherwise('Strong'))\n",
    "\n",
    "    # Comfort index (simplified heat index calculation)\n",
    "    df_transformed = df_transformed \\\n",
    "        .withColumn('heat_index',\n",
    "                   col('temperature') + 0.5 * (col('humidity') / 100) *\\\n",
    "                   (col('temperature') - 14.5)) \\\n",
    "        .withColumn('comfort_score',\n",
    "                   when((col('temperature').between(18, 24)) &\\\n",
    "                        (col('humidity').between(30, 60)) &\\\n",
    "                        (col('wind_speed') < 10), 100)\\\n",
    "                   .otherwise(100 - abs(col('temperature') - 21) * 3 -\\\n",
    "                             abs(col('humidity') - 50) * 0.5))\n",
    "\n",
    "    # Weather severity score\n",
    "    df_transformed = df_transformed \\\n",
    "        .withColumn('weather_severity',\n",
    "                   (col('wind_speed') / 5) +\\\n",
    "                   (col('rain_1h') * 2) +\\\n",
    "                   (col('snow_1h') * 3) +\\\n",
    "                   when(col('visibility') < 1000, 5).otherwise(0))\n",
    "\n",
    "    # Window functions for ranking\n",
    "    window_temp = Window.orderBy(col('temperature').desc())\n",
    "    window_humidity = Window.orderBy(col('humidity').desc())\n",
    "\n",
    "    df_transformed = df_transformed \\\n",
    "        .withColumn('temp_rank', rank().over(window_temp)) \\\n",
    "        .withColumn('humidity_rank', rank().over(window_humidity))\n",
    "\n",
    "    # Hemisphere classification\n",
    "    df_transformed = df_transformed \\\n",
    "        .withColumn('hemisphere',\n",
    "                   when(col('latitude') >= 0, 'Northern').otherwise('Southern'))\n",
    "\n",
    "    return df_transformed\n",
    "\n",
    "# Apply transformations\n",
    "df_processed = transform_weather_data(df_raw)\n",
    "print(f\"Transformed DataFrame: {df_processed.count()} rows, {len(df_processed.columns)} columns\")\n",
    "print(\"\\nNew columns added during transformation:\")\n",
    "new_cols = set(df_processed.columns) - set(df_raw.columns)\n",
    "print(\", \".join(sorted(new_cols)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3636220",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8: Data Quality Checks\n",
    "def perform_quality_checks(df):\n",
    "    \"\"\"Comprehensive data quality validation\"\"\"\n",
    "\n",
    "    checks = {}\n",
    "\n",
    "    # Null checks\n",
    "    null_counts = df.select([\n",
    "        sum(col(c).isNull().cast(\"int\")).alias(c)\n",
    "        for c in df.columns\n",
    "    ])\n",
    "    checks['null_check'] = null_counts\n",
    "\n",
    "    # Range checks\n",
    "    checks['temp_range'] = df.filter(\n",
    "        (col('temperature') < -50) | (col('temperature') > 60)\n",
    "    ).count()\n",
    "\n",
    "    checks['humidity_range'] = df.filter(\n",
    "        (col('humidity') < 0) | (col('humidity') > 100)\n",
    "    ).count()\n",
    "\n",
    "    checks['pressure_range'] = df.filter(\n",
    "        (col('pressure') < 900) | (col('pressure') > 1100)\n",
    "    ).count()\n",
    "\n",
    "    # Duplicate checks\n",
    "    checks['duplicate_cities'] = df.count() - df.select('city', 'country').distinct().count()\n",
    "\n",
    "    # Completeness check\n",
    "    checks['total_records'] = df.count()\n",
    "    checks['complete_records'] = df.dropna().count()\n",
    "    checks['completeness_pct'] = (checks['complete_records'] / checks['total_records']) * 100\n",
    "\n",
    "    return checks\n",
    "\n",
    "quality_results = perform_quality_checks(df_processed)\n",
    "\n",
    "print(\"=== Data Quality Report ===\\n\")\n",
    "print(f\"Total records: {quality_results['total_records']}\")\n",
    "print(f\"Complete records: {quality_results['complete_records']}\")\n",
    "print(f\"Completeness: {quality_results['completeness_pct']:.2f}%\\n\")\n",
    "\n",
    "print(\"Range validation issues:\")\n",
    "print(f\"  Temperature outliers: {quality_results['temp_range']}\")\n",
    "print(f\"  Humidity outliers: {quality_results['humidity_range']}\")\n",
    "print(f\"  Pressure outliers: {quality_results['pressure_range']}\")\n",
    "print(f\"  Duplicate cities: {quality_results['duplicate_cities']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "209b5691",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 9: Create Star Schema (Data Warehouse)\n",
    "def create_star_schema(df):\n",
    "    \"\"\"Build dimensional model for analytics\"\"\"\n",
    "\n",
    "    # Dimension: City (Type 1 SCD)\n",
    "    dim_city = df.select(\n",
    "        'city', 'country', 'latitude', 'longitude',\n",
    "        'timezone', 'hemisphere'\n",
    "    ).distinct() \\\n",
    "     .withColumn('city_key', monotonically_increasing_id())\n",
    "\n",
    "    # Dimension: Weather Condition\n",
    "    dim_weather = df.select(\n",
    "        'weather_main', 'weather_description'\n",
    "    ).distinct() \\\n",
    "     .withColumn('weather_key', monotonically_increasing_id())\n",
    "\n",
    "    # Dimension: Date\n",
    "    dim_date = df.select('date').distinct() \\\n",
    "        .withColumn('year', year('date')) \\\n",
    "        .withColumn('month', month('date')) \\\n",
    "        .withColumn('day', dayofmonth('date')) \\\n",
    "        .withColumn('quarter', quarter('date')) \\\n",
    "        .withColumn('day_of_week_num', dayofweek('date')) \\\n",
    "        .withColumn('day_name', date_format('date', 'EEEE')) \\\n",
    "        .withColumn('month_name', date_format('date', 'MMMM')) \\\n",
    "        .withColumn('week_of_year', weekofyear('date')) \\\n",
    "        .withColumn('is_weekend',\n",
    "                   when(dayofweek('date').isin([1, 7]), True).otherwise(False)) \\\n",
    "        .withColumn('date_key', monotonically_increasing_id())\n",
    "\n",
    "    # Dimension: Time\n",
    "    dim_time = df.select('hour').distinct() \\\n",
    "        .withColumn('hour_12',\n",
    "                   when(col('hour') == 0, 12)\\\n",
    "                   .when(col('hour') <= 12, col('hour'))\\\n",
    "                   .otherwise(col('hour') - 12)) \\\n",
    "        .withColumn('am_pm', when(col('hour') < 12, 'AM').otherwise('PM')) \\\n",
    "        .withColumn('time_of_day',\n",
    "                   when(col('hour').between(6, 11), 'Morning')\\\n",
    "                   .when(col('hour').between(12, 17), 'Afternoon')\\\n",
    "                   .when(col('hour').between(18, 21), 'Evening')\\\n",
    "                   .otherwise('Night')) \\\n",
    "        .withColumn('time_key', col('hour'))\n",
    "\n",
    "    # Fact Table: Weather Measurements\n",
    "    fact_weather = df.alias('f') \\\n",
    "        .join(broadcast(dim_city.alias('c')),\n",
    "              (col('f.city') == col('c.city')) &\\\n",
    "              (col('f.country') == col('c.country'))) \\\n",
    "        .join(broadcast(dim_weather.alias('w')),\n",
    "              col('f.weather_main') == col('w.weather_main')) \\\n",
    "        .join(broadcast(dim_date.alias('d')),\n",
    "              col('f.date') == col('d.date')) \\\n",
    "        .join(broadcast(dim_time.alias('t')),\n",
    "              col('f.hour') == col('t.hour')) \\\n",
    "        .select(\n",
    "            col('c.city_key'),\n",
    "            col('w.weather_key'),\n",
    "            col('d.date_key'),\n",
    "            col('t.time_key'),\n",
    "            col('f.datetime').alias('measurement_datetime'),\n",
    "            col('f.temperature'),\n",
    "            col('f.feels_like'),\n",
    "            col('f.temp_min'),\n",
    "            col('f.temp_max'),\n",
    "            col('f.temp_range'),\n",
    "            col('f.pressure'),\n",
    "            col('f.humidity'),\n",
    "            col('f.wind_speed'),\n",
    "            col('f.wind_deg'),\n",
    "            col('f.clouds'),\n",
    "            col('f.visibility_km'),\n",
    "            col('f.rain_1h'),\n",
    "            col('f.snow_1h'),\n",
    "            col('f.heat_index'),\n",
    "            col('f.comfort_score'),\n",
    "            col('f.weather_severity')\n",
    "        ) \\\n",
    "        .withColumn('fact_key', monotonically_increasing_id())\n",
    "\n",
    "    return {\n",
    "        'dim_city': dim_city,\n",
    "        'dim_weather': dim_weather,\n",
    "        'dim_date': dim_date,\n",
    "        'dim_time': dim_time,\n",
    "        'fact_weather': fact_weather\n",
    "    }\n",
    "\n",
    "# Build star schema\n",
    "warehouse = create_star_schema(df_processed)\n",
    "\n",
    "print(\"=== Data Warehouse Star Schema ===\\n\")\n",
    "for table_name, table_df in warehouse.items():\n",
    "    print(f\"{table_name}: {table_df.count()} rows\")\n",
    "    table_df.show(3)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb01982",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 10: Analytics - Aggregations and Insights\n",
    "# Temperature Analysis\n",
    "temp_analysis = df_processed.groupBy('city', 'country') \\\n",
    "    .agg(\n",
    "        round(avg('temperature'), 2).alias('avg_temp'),\n",
    "        round(min('temperature'), 2).alias('min_temp'),\n",
    "        round(max('temperature'), 2).alias('max_temp'),\n",
    "        round(stddev('temperature'), 2).alias('stddev_temp'),\n",
    "        round(avg('feels_like'), 2).alias('avg_feels_like'),\n",
    "        round(avg('humidity'), 1).alias('avg_humidity')\n",
    "    ) \\\n",
    "    .orderBy(col('avg_temp').desc())\n",
    "\n",
    "print(\"=== Temperature Analysis by City ===\")\n",
    "temp_analysis.show(truncate=False)\n",
    "\n",
    "# Weather Condition Distribution\n",
    "weather_dist = df_processed.groupBy('weather_main', 'weather_description') \\\n",
    "    .count() \\\n",
    "    .orderBy(col('count').desc())\n",
    "\n",
    "print(\"\\n=== Weather Condition Distribution ===\")\n",
    "weather_dist.show()\n",
    "\n",
    "# Hemisphere Comparison\n",
    "hemisphere_stats = df_processed.groupBy('hemisphere') \\\n",
    "    .agg(\n",
    "        round(avg('temperature'), 2).alias('avg_temp'),\n",
    "        round(avg('humidity'), 1).alias('avg_humidity'),\n",
    "        round(avg('wind_speed'), 2).alias('avg_wind'),\n",
    "        count('*').alias('city_count')\n",
    "    )\n",
    "\n",
    "print(\"\\n=== Hemisphere Comparison ===\")\n",
    "hemisphere_stats.show()\n",
    "\n",
    "# Comfort Score Ranking\n",
    "comfort_ranking = df_processed.select(\n",
    "    'city', 'country', 'temperature', 'humidity',\n",
    "    'wind_speed', 'comfort_score'\n",
    ").orderBy(col('comfort_score').desc())\n",
    "\n",
    "print(\"\\n=== Most Comfortable Cities ===\")\n",
    "comfort_ranking.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f66c4410",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 11: Advanced Analytics - Window Functions\n",
    "# Running averages and percentiles\n",
    "window_spec = Window.orderBy('temperature')\n",
    "\n",
    "advanced_stats = df_processed.select(\n",
    "    'city',\n",
    "    'temperature',\n",
    "    'humidity',\n",
    "    round(avg('temperature').over(window_spec), 2).alias('running_avg_temp'),\n",
    "    percent_rank().over(window_spec).alias('temp_percentile'),\n",
    "    ntile(4).over(window_spec).alias('temp_quartile')\n",
    ").orderBy('temperature')\n",
    "\n",
    "print(\"=== Advanced Analytics with Window Functions ===\")\n",
    "advanced_stats.show(10)\n",
    "\n",
    "# Correlation analysis\n",
    "correlations = df_processed.select(\n",
    "    'temperature', 'humidity', 'pressure',\n",
    "    'wind_speed', 'clouds', 'visibility_km'\n",
    ").toPandas().corr()\n",
    "\n",
    "print(\"\\n=== Correlation Matrix ===\")\n",
    "print(correlations.round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe3aac84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 12: Visualization - Temperature Distribution\n",
    "pdf = df_processed.select(\n",
    "    'city', 'country', 'temperature', 'humidity',\n",
    "    'wind_speed', 'weather_main', 'temp_category',\n",
    "    'latitude', 'longitude', 'comfort_score'\n",
    ").toPandas()\n",
    "\n",
    "# Temperature by city\n",
    "fig1 = px.bar(\n",
    "    pdf.sort_values('temperature', ascending=False),\n",
    "    x='city',\n",
    "    y='temperature',\n",
    "    color='temperature',\n",
    "    title='Temperature by City',\n",
    "    labels={'temperature': 'Temperature (Â°C)'},\n",
    "    color_continuous_scale='RdYlBu_r',\n",
    "    text='temperature'\n",
    ")\n",
    "fig1.update_traces(texttemplate='%{text:.1f}Â°C', textposition='outside')\n",
    "fig1.update_layout(showlegend=False, xaxis_tickangle=-45)\n",
    "fig1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df5acb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 13: Visualization - Multi-metric Dashboard\n",
    "fig2 = make_subplots(\n",
    "    rows=2, cols=2,\n",
    "    subplot_titles=('Temperature vs Humidity', 'Wind Speed Distribution',\n",
    "                    'Weather Conditions', 'Comfort Score Ranking'),\n",
    "    specs=[[{'type': 'scatter'}, {'type': 'bar'}],\n",
    "           [{'type': 'pie'}, {'type': 'bar'}]]\n",
    ")\n",
    "\n",
    "# Scatter: Temp vs Humidity\n",
    "fig2.add_trace(\n",
    "    go.Scatter(x=pdf['temperature'], y=pdf['humidity'],\n",
    "               mode='markers+text', text=pdf['city'],\n",
    "               textposition='top center',\n",
    "               marker=dict(size=10, color=pdf['wind_speed'],\n",
    "                          colorscale='Viridis', showscale=True)),\n",
    "    row=1, col=1\n",
    ")\n",
    "\n",
    "# Bar: Wind Speed\n",
    "fig2.add_trace(\n",
    "    go.Bar(x=pdf['city'], y=pdf['wind_speed'],\n",
    "           marker_color='lightblue'),\n",
    "    row=1, col=2\n",
    ")\n",
    "\n",
    "# Pie: Weather Conditions\n",
    "weather_counts = pdf['weather_main'].value_counts()\n",
    "fig2.add_trace(\n",
    "    go.Pie(labels=weather_counts.index, values=weather_counts.values),\n",
    "    row=2, col=1\n",
    ")\n",
    "\n",
    "# Bar: Comfort Score\n",
    "top_comfort = pdf.nlargest(10, 'comfort_score')\n",
    "fig2.add_trace(\n",
    "    go.Bar(x=top_comfort['city'], y=top_comfort['comfort_score'],\n",
    "           marker_color='lightgreen'),\n",
    "    row=2, col=2\n",
    ")\n",
    "\n",
    "fig2.update_xaxes(title_text=\"Temperature (Â°C)\", row=1, col=1)\n",
    "fig2.update_yaxes(title_text=\"Humidity (%)\", row=1, col=1)\n",
    "fig2.update_xaxes(tickangle=-45, row=1, col=2)\n",
    "fig2.update_xaxes(tickangle=-45, row=2, col=2)\n",
    "\n",
    "fig2.update_layout(height=800, showlegend=False,\n",
    "                   title_text=\"Weather Analytics Dashboard\")\n",
    "fig2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "578bd7e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 14: Geographic Visualization\n",
    "fig3 = px.scatter_geo(\n",
    "    pdf,\n",
    "    lat='latitude',\n",
    "    lon='longitude',\n",
    "    hover_name='city',\n",
    "    hover_data={\n",
    "        'temperature': ':.1f',\n",
    "        'humidity': ':.0f',\n",
    "        'wind_speed': ':.1f',\n",
    "        'latitude': False,\n",
    "        'longitude': False\n",
    "    },\n",
    "    color='temperature',\n",
    "    size='comfort_score',\n",
    "    color_continuous_scale='RdYlBu_r',\n",
    "    title='Global Weather Map',\n",
    "    size_max=20\n",
    ")\n",
    "fig3.update_layout(geo=dict(showland=True, landcolor='lightgray'))\n",
    "fig3.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c44d8705",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 15: Export Results\n",
    "# Convert to Pandas for export\n",
    "export_df = df_processed.select(\n",
    "    'city', 'country', 'datetime', 'temperature', 'feels_like',\n",
    "    'humidity', 'pressure', 'wind_speed', 'weather_main',\n",
    "    'weather_description', 'temp_category', 'comfort_score',\n",
    "    'weather_severity', 'hemisphere'\n",
    ").toPandas()\n",
    "\n",
    "# Save to CSV\n",
    "export_df.to_csv('weather_data_processed.csv', index=False)\n",
    "print(\"âœ“ Processed data exported to: weather_data_processed.csv\")\n",
    "\n",
    "# Export warehouse tables\n",
    "for table_name, table_df in warehouse.items():\n",
    "    pandas_df = table_df.toPandas()\n",
    "    filename = f'{table_name}.csv'\n",
    "    pandas_df.to_csv(filename, index=False)\n",
    "    print(f\"âœ“ {table_name} exported to: {filename}\")\n",
    "\n",
    "# Summary statistics\n",
    "summary = pdf.describe()\n",
    "summary.to_csv('weather_summary_stats.csv')\n",
    "print(\"âœ“ Summary statistics exported to: weather_summary_stats.csv\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Pipeline Complete! All files exported successfully.\")\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e76b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 16: Pipeline Summary and Insights\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"WEATHER DATA ENGINEERING PIPELINE - SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"\\nðŸ“Š Data Processing Stats:\")\n",
    "print(f\"   â€¢ Cities analyzed: {df_processed.select('city').distinct().count()}\")\n",
    "print(f\"   â€¢ Total records: {df_processed.count()}\")\n",
    "print(f\"   â€¢ Features engineered: {len(df_processed.columns)}\")\n",
    "print(f\"   â€¢ Quality checks passed: All critical validations âœ“\")\n",
    "\n",
    "print(f\"\\nðŸŒ¡ï¸  Temperature Insights:\")\n",
    "hottest = pdf.loc[pdf['temperature'].idxmax()]\n",
    "coldest = pdf.loc[pdf['temperature'].idxmin()]\n",
    "print(f\"   â€¢ Hottest: {hottest['city']} ({hottest['temperature']:.1f}Â°C)\")\n",
    "print(f\"   â€¢ Coldest: {coldest['city']} ({coldest['temperature']:.1f}Â°C)\")\n",
    "print(f\"   â€¢ Average: {pdf['temperature'].mean():.1f}Â°C\")\n",
    "\n",
    "print(f\"\\nðŸ† Most Comfortable City:\")\n",
    "best = pdf.loc[pdf['comfort_score'].idxmax()]\n",
    "print(f\"   â€¢ {best['city']}, {best['country']}\")\n",
    "print(f\"   â€¢ Comfort Score: {best['comfort_score']:.1f}/100\")\n",
    "print(f\"   â€¢ Temp: {best['temperature']:.1f}Â°C, Humidity: {best['humidity']:.0f}%\")\n",
    "\n",
    "print(f\"\\nðŸ—ï¸  Data Warehouse:\")\n",
    "print(f\"   â€¢ Star schema implemented âœ“\")\n",
    "print(f\"   â€¢ Dimension tables: 4\")\n",
    "print(f\"   â€¢ Fact table records: {warehouse['fact_weather'].count()}\")\n",
    "\n",
    "print(f\"\\nðŸ“ Exported Files:\")\n",
    "print(f\"   â€¢ weather_data_processed.csv\")\n",
    "print(f\"   â€¢ dim_city.csv, dim_weather.csv, dim_date.csv, dim_time.csv\")\n",
    "print(f\"   â€¢ fact_weather.csv\")\n",
    "print(f\"   â€¢ weather_summary_stats.csv\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"âœ… Pipeline executed successfully!\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
