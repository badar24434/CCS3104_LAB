{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e320ee9",
   "metadata": {},
   "source": [
    "# Weather Data Engineering Pipeline - Google Colab Version\n",
    "# =========================================================\n",
    "Run this notebook in Google Colab for a complete data engineering workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d865e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Setup and Installation\n",
    "print(\"Installing dependencies...\")\n",
    "!pip install -q pyspark requests great-expectations plotly sqlalchemy\n",
    "\n",
    "print(\"Setup complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "886d70b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Import Libraries\n",
    "import requests\n",
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.window import Window\n",
    "import json\n",
    "from datetime import datetime\n",
    "import time\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d682cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Initialize Spark Session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"WeatherPipeline\") \\\n",
    "    .config(\"spark.sql.repl.eagerEval.enabled\", True) \\\n",
    "    .config(\"spark.driver.memory\", \"4g\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")\n",
    "print(f\"Spark version: {spark.version}\")\n",
    "print(\"Spark session initialized!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf2a13a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Configuration\n",
    "# Get your free API key from: https://openweathermap.org/api\n",
    "API_KEY = \"34a91dc9a353902fd151448547fde35c\"  # Replace with your API key\n",
    "\n",
    "CITIES = [\n",
    "    \"London,UK\", \"New York,US\", \"Tokyo,JP\", \"Paris,FR\",\n",
    "    \"Sydney,AU\", \"Mumbai,IN\", \"Singapore,SG\", \"Dubai,AE\",\n",
    "    \"Toronto,CA\", \"Berlin,DE\", \"São Paulo,BR\", \"Moscow,RU\"\n",
    "]\n",
    "\n",
    "BASE_URL = \"http://api.openweathermap.org/data/2.5/weather\"\n",
    "\n",
    "print(f\"Pipeline configured for {len(CITIES)} cities\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de4aab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Extract - Fetch Weather Data from API\n",
    "def extract_weather_data(api_key, cities, base_url):\n",
    "    \"\"\"Extract current weather data from OpenWeatherMap API\"\"\"\n",
    "    weather_data = []\n",
    "    failed_cities = []\n",
    "\n",
    "    print(f\"Extracting data for {len(cities)} cities...\")\n",
    "\n",
    "    for city in cities:\n",
    "        try:\n",
    "            params = {\n",
    "                'q': city,\n",
    "                'appid': api_key,\n",
    "                'units': 'metric'\n",
    "            }\n",
    "            response = requests.get(base_url, params=params, timeout=10)\n",
    "            response.raise_for_status()\n",
    "            data = response.json()\n",
    "\n",
    "            # Flatten nested JSON structure\n",
    "            # Ensure numeric fields that might vary between int/float are cast to float for consistent schema inference\n",
    "            flattened = {\n",
    "                'city': data['name'],\n",
    "                'country': data['sys']['country'],\n",
    "                'latitude': float(data['coord']['lat']),\n",
    "                'longitude': float(data['coord']['lon']),\n",
    "                'temperature': float(data['main']['temp']),\n",
    "                'feels_like': float(data['main']['feels_like']),\n",
    "                'temp_min': float(data['main']['temp_min']),\n",
    "                'temp_max': float(data['main']['temp_max']),\n",
    "                'pressure': float(data['main']['pressure']),\n",
    "                'humidity': float(data['main']['humidity']),\n",
    "                'weather_main': data['weather'][0]['main'],\n",
    "                'weather_description': data['weather'][0]['description'],\n",
    "                'wind_speed': float(data['wind']['speed']),\n",
    "                'wind_deg': float(data['wind'].get('deg', 0)),\n",
    "                'clouds': float(data['clouds']['all']),\n",
    "                'visibility': float(data.get('visibility', 10000)),\n",
    "                'rain_1h': float(data.get('rain', {}).get('1h', 0)),\n",
    "                'snow_1h': float(data.get('snow', {}).get('1h', 0)),\n",
    "                'sunrise': float(data['sys']['sunrise']),\n",
    "                'sunset': float(data['sys']['sunset']),\n",
    "                'timezone': float(data['timezone']),\n",
    "                'timestamp': float(data['dt']),\n",
    "                'extraction_time': datetime.now().isoformat()\n",
    "            }\n",
    "            weather_data.append(flattened)\n",
    "            print(f\"✓ {city}\")\n",
    "            time.sleep(0.3)  # Rate limiting\n",
    "\n",
    "        except Exception as e:\n",
    "            failed_cities.append(city)\n",
    "            print(f\"✗ {city}: {str(e)}\")\n",
    "\n",
    "    print(f\"\\nSuccessfully extracted: {len(weather_data)}/{len(cities)} cities\")\n",
    "    if failed_cities:\n",
    "        print(f\"Failed cities: {', '.join(failed_cities)}\")\n",
    "\n",
    "    return weather_data\n",
    "\n",
    "# Execute extraction\n",
    "raw_data = extract_weather_data(API_KEY, CITIES, BASE_URL)\n",
    "\n",
    "# Display sample\n",
    "if raw_data:\n",
    "    print(\"\\nSample raw data:\")\n",
    "    print(json.dumps(raw_data[0], indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b375c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Load Raw Data into Spark DataFrame\n",
    "if not raw_data:\n",
    "    raise ValueError(\"No data extracted! Check your API key and internet connection.\")\n",
    "\n",
    "df_raw = spark.createDataFrame(raw_data)\n",
    "print(f\"Raw DataFrame created with {df_raw.count()} rows and {len(df_raw.columns)} columns\")\n",
    "print(\"\\nSchema:\")\n",
    "df_raw.printSchema()\n",
    "print(\"\\nSample data:\")\n",
    "df_raw.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c7ea0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Transform - Data Processing with PySpark\n",
    "def transform_weather_data(df):\n",
    "    \"\"\"Apply comprehensive transformations to weather data\"\"\"\n",
    "\n",
    "    # Datetime conversions\n",
    "    df_transformed = df \\\n",
    "        .withColumn('date', from_unixtime(col('timestamp')).cast('date')) \\\n",
    "        .withColumn('datetime', from_unixtime(col('timestamp')).cast('timestamp')) \\\n",
    "        .withColumn('hour', hour(from_unixtime(col('timestamp')))) \\\n",
    "        .withColumn('day_of_week', date_format(from_unixtime(col('timestamp')), 'EEEE')) \\\n",
    "        .withColumn('sunrise_time', from_unixtime(col('sunrise')).cast('timestamp')) \\\n",
    "        .withColumn('sunset_time', from_unixtime(col('sunset')).cast('timestamp'))\n",
    "\n",
    "    # Derived metrics\n",
    "    df_transformed = df_transformed \\\n",
    "        .withColumn('temp_range', col('temp_max') - col('temp_min')) \\\n",
    "        .withColumn('is_raining', when(col('rain_1h') > 0, True).otherwise(False)) \\\n",
    "        .withColumn('is_snowing', when(col('snow_1h') > 0, True).otherwise(False)) \\\n",
    "        .withColumn('visibility_km', col('visibility') / 1000)\n",
    "\n",
    "    # Categorizations\n",
    "    df_transformed = df_transformed \\\n",
    "        .withColumn('temp_category',\n",
    "                   when(col('temperature') < 0, 'Freezing')\\\n",
    "                   .when(col('temperature') < 10, 'Cold')\\\n",
    "                   .when(col('temperature') < 20, 'Cool')\\\n",
    "                   .when(col('temperature') < 25, 'Moderate')\\\n",
    "                   .when(col('temperature') < 30, 'Warm')\\\n",
    "                   .otherwise('Hot')) \\\n",
    "        .withColumn('humidity_category',\n",
    "                   when(col('humidity') < 30, 'Low')\\\n",
    "                   .when(col('humidity') < 60, 'Moderate')\\\n",
    "                   .otherwise('High')) \\\n",
    "        .withColumn('wind_category',\n",
    "                   when(col('wind_speed') < 5, 'Calm')\\\n",
    "                   .when(col('wind_speed') < 10, 'Light')\\\n",
    "                   .when(col('wind_speed') < 20, 'Moderate')\\\n",
    "                   .otherwise('Strong'))\n",
    "\n",
    "    # Comfort index (simplified heat index calculation)\n",
    "    df_transformed = df_transformed \\\n",
    "        .withColumn('heat_index',\n",
    "                   col('temperature') + 0.5 * (col('humidity') / 100) *\\\n",
    "                   (col('temperature') - 14.5)) \\\n",
    "        .withColumn('comfort_score',\n",
    "                   when((col('temperature').between(18, 24)) &\\\n",
    "                        (col('humidity').between(30, 60)) &\\\n",
    "                        (col('wind_speed') < 10), 100)\\\n",
    "                   .otherwise(100 - abs(col('temperature') - 21) * 3 -\\\n",
    "                             abs(col('humidity') - 50) * 0.5))\n",
    "\n",
    "    # Weather severity score\n",
    "    df_transformed = df_transformed \\\n",
    "        .withColumn('weather_severity',\n",
    "                   (col('wind_speed') / 5) +\\\n",
    "                   (col('rain_1h') * 2) +\\\n",
    "                   (col('snow_1h') * 3) +\\\n",
    "                   when(col('visibility') < 1000, 5).otherwise(0))\n",
    "\n",
    "    # Window functions for ranking\n",
    "    window_temp = Window.orderBy(col('temperature').desc())\n",
    "    window_humidity = Window.orderBy(col('humidity').desc())\n",
    "\n",
    "    df_transformed = df_transformed \\\n",
    "        .withColumn('temp_rank', rank().over(window_temp)) \\\n",
    "        .withColumn('humidity_rank', rank().over(window_humidity))\n",
    "\n",
    "    # Hemisphere classification\n",
    "    df_transformed = df_transformed \\\n",
    "        .withColumn('hemisphere',\n",
    "                   when(col('latitude') >= 0, 'Northern').otherwise('Southern'))\n",
    "\n",
    "    return df_transformed\n",
    "\n",
    "# Apply transformations\n",
    "df_processed = transform_weather_data(df_raw)\n",
    "print(f\"Transformed DataFrame: {df_processed.count()} rows, {len(df_processed.columns)} columns\")\n",
    "print(\"\\nNew columns added during transformation:\")\n",
    "new_cols = set(df_processed.columns) - set(df_raw.columns)\n",
    "print(\", \".join(sorted(new_cols)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3636220",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8: Data Quality Checks\n",
    "def perform_quality_checks(df):\n",
    "    \"\"\"Comprehensive data quality validation\"\"\"\n",
    "\n",
    "    checks = {}\n",
    "\n",
    "    # Null checks\n",
    "    null_counts = df.select([\n",
    "        sum(col(c).isNull().cast(\"int\")).alias(c)\n",
    "        for c in df.columns\n",
    "    ])\n",
    "    checks['null_check'] = null_counts\n",
    "\n",
    "    # Range checks\n",
    "    checks['temp_range'] = df.filter(\n",
    "        (col('temperature') < -50) | (col('temperature') > 60)\n",
    "    ).count()\n",
    "\n",
    "    checks['humidity_range'] = df.filter(\n",
    "        (col('humidity') < 0) | (col('humidity') > 100)\n",
    "    ).count()\n",
    "\n",
    "    checks['pressure_range'] = df.filter(\n",
    "        (col('pressure') < 900) | (col('pressure') > 1100)\n",
    "    ).count()\n",
    "\n",
    "    # Duplicate checks\n",
    "    checks['duplicate_cities'] = df.count() - df.select('city', 'country').distinct().count()\n",
    "\n",
    "    # Completeness check\n",
    "    checks['total_records'] = df.count()\n",
    "    checks['complete_records'] = df.dropna().count()\n",
    "    checks['completeness_pct'] = (checks['complete_records'] / checks['total_records']) * 100\n",
    "\n",
    "    return checks\n",
    "\n",
    "quality_results = perform_quality_checks(df_processed)\n",
    "\n",
    "print(\"=== Data Quality Report ===\\n\")\n",
    "print(f\"Total records: {quality_results['total_records']}\")\n",
    "print(f\"Complete records: {quality_results['complete_records']}\")\n",
    "print(f\"Completeness: {quality_results['completeness_pct']:.2f}%\\n\")\n",
    "\n",
    "print(\"Range validation issues:\")\n",
    "print(f\"  Temperature outliers: {quality_results['temp_range']}\")\n",
    "print(f\"  Humidity outliers: {quality_results['humidity_range']}\")\n",
    "print(f\"  Pressure outliers: {quality_results['pressure_range']}\")\n",
    "print(f\"  Duplicate cities: {quality_results['duplicate_cities']}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
